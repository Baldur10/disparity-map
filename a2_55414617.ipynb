{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4186 Computer Vision and Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psnr_cal\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder Paths\n",
    "imageFolder = './StereoMatchingTestings/'\n",
    "predictionsFolder = './pred/'\n",
    "imageStatPath = './imagestats/'\n",
    "\n",
    "# Class of Images / Name of image folder\n",
    "imagesCategory = [\"Art\", \"Dolls\", \"Reindeer\"]\n",
    "\n",
    "# Images\n",
    "view1 = 'view1.png'\n",
    "view5 = 'view5.png'\n",
    "\n",
    "# Feature Matcher \n",
    "matcher = \"flann\"\n",
    "\n",
    "# Threshold\n",
    "BEST_MATCHES_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesMatrix = []\n",
    "for specificImage in imagesCategory:\n",
    "    image1Path = imageFolder + specificImage + '/' + view1\n",
    "    image2Path = imageFolder + specificImage + '/' + view5\n",
    "    try:\n",
    "        img1 = cv2.imread(image1Path, cv2.IMREAD_GRAYSCALE)\n",
    "        img2 = cv2.imread(image2Path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        imagePair = (img1,img2)\n",
    "        imagesMatrix.append(imagePair)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Encounted error: {}\".format(e))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagesMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIFT Descriptor Disparity Map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.isdir(imageStatPath):\n",
    "        os.mkdir(imageStatPath)\n",
    "\n",
    "img_index = 0\n",
    "\n",
    "for imagePair in imagesMatrix:\n",
    "\n",
    "        siftDescriptor = cv2.SIFT_create()\n",
    "\n",
    "        combinedCurrentPath = imageStatPath + imagesCategory[img_index]\n",
    "        if not os.path.isdir(combinedCurrentPath):\n",
    "                os.mkdir(combinedCurrentPath)\n",
    "  \n",
    "\n",
    "        # Extract the kepoints and descriptors\n",
    "        keyPoint1, des1 = siftDescriptor.detectAndCompute(imagePair[0], None)\n",
    "        keyPoint2, des2 = siftDescriptor.detectAndCompute(imagePair[1], None)\n",
    "\n",
    "        # Display all generated keypoints\n",
    "        imageShift = cv2.drawKeypoints(imagePair[0], keyPoint1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        # if \n",
    "        # plt.imshow(imageShift)\n",
    "        # plt.show()\n",
    "        # cv2.imshow(\"SIFT_keypoints\",imageShift)\n",
    "        cv2.imwrite(combinedCurrentPath + \"/SIFT_keypoints.png\", imageShift)\n",
    "\n",
    "        # Perform keypoint matching\n",
    "        if matcher == \"flann\":\n",
    "                params_index = dict(algorithm=1,trees=5)\n",
    "                params_search = dict(checks=50)\n",
    "                matches_found = cv2.FlannBasedMatcher(params_index, params_search).knnMatch(des1,des2, 2)\n",
    "        elif matcher == \"bf\":\n",
    "            matches_found = cv2.BFMatcher(cv2.NORM_L2).knnMatch(des1,des2, 2)\n",
    "        else:\n",
    "            print('Invalid matcher parameter set. Resorting to BruteForce matcher with NORM L2 distance measure.')\n",
    "            matches_found = cv2.BFMatcher(cv2.NORM_L2).knnMatch(des1,des2, 2)\n",
    "\n",
    "        # Filtering for best matches\n",
    "        mask = [[0,0] for i in range(len(matches_found))]\n",
    "        matches_feasible = []\n",
    "        pointSet1 = []\n",
    "        pointSet2 = []\n",
    "        \n",
    "        for i, (m,n) in enumerate(matches_found):\n",
    "                if m.distance < BEST_MATCHES_THRESHOLD * n.distance:\n",
    "                        mask[i] = [1,0]\n",
    "                        matches_feasible.append([m])\n",
    "                        pointSet1.append(keyPoint1[m.queryIdx].pt)\n",
    "                        # print(np.array(keyPoint1[m.queryIdx].pt).shape)\n",
    "                        pointSet2.append(keyPoint2[m.trainIdx].pt)\n",
    "                        # print(np.array(keyPoint2[m.trainIdx].pt).shape)\n",
    "        \n",
    "        # print(np.array(matches_found).shape)\n",
    "        # print(np.array(matches_feasible).shape)\n",
    "        # print(np.array(keyPoint1).shape)\n",
    "        # print(np.array(keyPoint2).shape)\n",
    "\n",
    "        # Plotting keypoints\n",
    "        params_sketch = dict(matchColor=(0, 255, 0), singlePointColor=(255,0,0),matchesMask=mask[300:500],flags=cv2.DrawMatchesFlags_DEFAULT)\n",
    "        matches_feasible_keypoints = cv2.drawMatchesKnn(imagePair[0], keyPoint1, imagePair[1], keyPoint2, matches_feasible[300:500], None, **params_sketch)\n",
    "        # cv2.imshow(\"matches_feasible\", matches_feasible_keypoints)\n",
    "        cv2.imwrite(combinedCurrentPath + \"/matches_feasible.png\", matches_feasible_keypoints)\n",
    "\n",
    "        # Calculating Fundamental Matrix and selecting inlining values\n",
    "        pointSet1 = np.int32(pointSet1)\n",
    "        pointSet2 = np.int32(pointSet2)\n",
    "\n",
    "        fm, inliers = cv2.findFundamentalMat(np.int32(pointSet1), np.int32(pointSet2), cv2.FM_RANSAC)\n",
    "        \n",
    "        pointSet1 = pointSet1[inliers.ravel() == 1]\n",
    "        pointSet2 = pointSet2[inliers.ravel() == 1]\n",
    "\n",
    "        firstEpiLine = cv2.computeCorrespondEpilines(pointSet2.reshape(-1, 1, 2), 2, fm).reshape(-1,3)\n",
    "        secondEpiLine = cv2.computeCorrespondEpilines(pointSet1.reshape(-1, 1, 2), 2, fm).reshape(-1,3)\n",
    "\n",
    "        height1, width1 = imagePair[0].shape\n",
    "        height2, width2 = imagePair[1].shape\n",
    "\n",
    "        _, filter1, filter2 = cv2.stereoRectifyUncalibrated(\n",
    "                np.float32(pointSet1), np.float32(pointSet2), fm, imgSize=(width1, height1)\n",
    "        )\n",
    "\n",
    "        # Rectify the images\n",
    "        img1_fixed = cv2.warpPerspective(imagePair[0], filter1, (width1, height1))\n",
    "        cv2.imwrite(combinedCurrentPath + \"/view1_rectified.png\", img1_fixed)\n",
    "\n",
    "        img2_fixed = cv2.warpPerspective(imagePair[1], filter2, (width2, height2))\n",
    "        cv2.imwrite(combinedCurrentPath + \"/view2_rectified.png\", img2_fixed)\n",
    "\n",
    "        # Creating the stero object\n",
    "\n",
    "        windowSize = 3\n",
    "        bSize = 20\n",
    "        minDisp = -128\n",
    "        maxDisp = 128\n",
    "        nDisp = maxDisp - minDisp\n",
    "        disp12MaxDiff = 0\n",
    "        uRatio = 2\n",
    "        speckleWindowSize = 200\n",
    "        speckleRange = 2\n",
    "\n",
    "        stereo = cv2.StereoSGBM_create(\n",
    "                minDisparity=minDisp,\n",
    "                numDisparities=nDisp,\n",
    "                blockSize=bSize,\n",
    "                uniquenessRatio=uRatio,\n",
    "                speckleWindowSize=speckleWindowSize,\n",
    "                speckleRange=speckleRange,\n",
    "                disp12MaxDiff=disp12MaxDiff,\n",
    "                P1=8 * 1 * windowSize * 2,\n",
    "                P2=32 * 1 * windowSize * 2,\n",
    "        )  \n",
    "\n",
    "        disparity_SGBM = stereo.compute(img1_fixed, img2_fixed)\n",
    "\n",
    "        disparity_map = cv2.ximgproc.createRightMatcher(stereo).compute(img2_fixed,img1_fixed)\n",
    "\n",
    "        wls_filter = cv2.ximgproc.createDisparityWLSFilter(matcher_left=stereo)\n",
    "        wls_filter.setLambda(35000)\n",
    "        wls_filter.setSigmaColor(1.5)\n",
    "        filtered_disp = wls_filter.filter(disparity_SGBM, img1_fixed, disparity_map_right=disparity_map)\n",
    "        filtered_disp = cv2.normalize(filtered_disp, filtered_disp, alpha=255, beta=0, norm_type=cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(predictionsFolder + imagesCategory[img_index] + \"/disp1.png\", filtered_disp)\n",
    "        img_index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Peak-SNR value is %0.4f \n",
      " 5.334773826753589\n",
      "The Peak-SNR value is %0.4f \n",
      " 10.322574474920144\n",
      "The Peak-SNR value is %0.4f \n",
      " 12.580840080062183\n"
     ]
    }
   ],
   "source": [
    "psnr_cal.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04a20cc0f25f2654a5fc5715c026c4c293afbc25926c593c301cab56769943bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
